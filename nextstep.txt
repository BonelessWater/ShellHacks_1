Next steps to integrate components into a product
=================================================

Goal: Turn the current multi-agent fraud-detection suite into a maintainable,
deployable product with clear CI, data governance, and a lightweight API.

Milestones (high level)
1) Code hygiene & dependency management
   - Clean up compatibility shims (create `cleanup/` branch, update imports, remove shims)
   - Pin minimal production dependencies in `pyproject.toml`. Move heavy deps
     (TensorFlow) to optional extras.
   - Add static checks (ruff, mypy optional) and a pre-commit config.

2) Data access & security
   - Centralize BigQuery project/dataset configuration and document required
     IAM roles. Ensure service-account usage is documented and secrets are
     never committed.
   - Implement audit logs for any write operations and provide a test-mode
     that runs all writes into a sandbox dataset.

3) Component integration & API
   - Standardize internal data models (pydantic/dataclasses) and serialization.
   - Implement a lightweight Flask/FastAPI wrapper around the coordinator:
     POST /analyze -> runs coordinator (with timeouts) -> returns result.
   - Add async worker support (Celery/RQ) for long-running or batch jobs.

4) Testing & CI
   - Expand test matrix in CI: unit, integration (GCP), and smoke tests.
   - Mock external services where possible (LLM, BigQuery) and provide a
     gated integration pipeline that runs only with real credentials.

5) Observability & Deployment
   - Add structured logging, metrics (Prometheus), and tracing (optional).
   - Provide a Dockerfile and Helm chart (or k8s manifests) for deployment.

Concrete technical tasks (next 2-4 weeks)
- Week 1: Safety & cleanup
  - Create `backend/compat_cleanup.md` documenting each shim mapping.
  - Run a grep of `backend.` imports across repo; identify call sites.
  - Replace imports at call sites to reference `backend.archive.*` canonical
    locations or move the real implementations back to their expected module
    paths depending on final layout.
  - Remove shims in a cleanup PR.

- Week 2: API + worker
  - Implement `api/` FastAPI app with a single POST endpoint for analysis.
  - Add a small async worker (RQ) and a local Docker Compose file for dev.

- Week 3: CI + testing
  - Add GitHub Actions with a matrix that runs unit tests on PRs; separate
    integration workflow that runs only when `GCP_CREDENTIALS` are provided
    as secrets.
  - Add a small local test fixture to mock BigQuery responses (vcrpy or custom)
    for unit tests that would otherwise call GCP.

Acceptance criteria for MVP
- All unit tests pass on every PR.
- Integration tests can run on a gated workflow with a documented checklist
  for setting up credentials.
- The API provides a documented POST /analyze endpoint and returns JSON
  with a stable contract for agent results.

Risks and mitigations
- Risk: Sensitive data leakage via accidental commits. Mitigation: pre-commit
  and CI checks to block secrets, rotate any exposed keys immediately.
- Risk: Cost from running real BigQuery queries in CI. Mitigation: use
  mock datasets and have a separate, manually-triggered integration run.

Notes about LLM usage
- Treat LLM calls as non-deterministic: add safeguards, timeouts, and
  post-validation of outputs before writing to production datasets.
- Consider adding a lightweight local LLM or deterministic fallback for
  high-frequency checks where cost matters.

Owners & next moves
- Assign a small team (1-2 engineers) to Week 1 and Week 2 tasks.
- I can open the initial cleanup PR and the API skeleton if you want me to.
